{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfbd71b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/narger/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85447a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b574d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mask(starting_padding, ending_padding, window_length, max_length):\n",
    "    mask = []\n",
    "    for i in range(starting_padding):\n",
    "        mask.append(0)\n",
    "    while len(mask) < (max_length - ending_padding):\n",
    "        for j in range(window_length):\n",
    "            mask.append(1)\n",
    "        mask.append(0)\n",
    "        \n",
    "    while len(mask) > max_length:\n",
    "        mask.pop()\n",
    "    while len(mask) < max_length:\n",
    "        mask.append(0)\n",
    "        \n",
    "    for i in range(ending_padding):\n",
    "        mask[max_length - i - 1] = 0\n",
    "        \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633da4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 32\n",
    "padding = 1\n",
    "\n",
    "bin_mask1 = np.tile(np.array(build_mask(img_width + 1, 0, img_width -1, img_width ** 2)), 16)\n",
    "bin_mask2 = np.tile(np.array(build_mask(img_width, 0, img_width ** 2, img_width ** 2)), 16)\n",
    "bin_mask3 = np.tile(np.array(build_mask(img_width, 0, img_width - 1, img_width ** 2)), 16)\n",
    "bin_mask4 = np.tile(np.array(build_mask(1, 0, img_width - 1, img_width ** 2)), 16)\n",
    "bin_mask5 = np.tile(np.array(build_mask(0, 0, img_width ** 2, img_width ** 2)), 16)\n",
    "bin_mask6 = np.tile(np.array(build_mask(0, 1, img_width - 1, img_width ** 2)), 16)\n",
    "bin_mask7 = np.tile(np.array(build_mask(1, img_width - 1, img_width - 1, img_width ** 2)), 16)\n",
    "bin_mask8 = np.tile(np.array(build_mask(0, img_width, img_width ** 2, img_width ** 2)), 16)\n",
    "bin_mask9 = np.tile(np.array(build_mask(0, img_width + 1, img_width - 1, img_width ** 2)), 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e826a922",
   "metadata": {},
   "source": [
    "## Initial Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266ede8",
   "metadata": {},
   "source": [
    "This layer is particular, if interested in the workings of Algorithm 2, check Conv1+Bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96af4fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([0.1612, 0.0118, 0.3612, 0.1782, 0.4380, 0.3213, 0.3849, 0.2592, 0.4423,\n",
      "        0.2112, 0.0057, 0.2565, 0.3944, 0.1887, 0.2364, 0.4103],\n",
      "       grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([ 1.5648e-01, -1.5094e-03,  2.5889e-01,  2.2570e-01,  6.0322e-01,\n",
      "        -1.9860e-02,  2.1012e-01,  2.5123e-01,  2.7174e-01,  1.6638e-01,\n",
      "        -9.3954e-05,  2.8412e-01, -5.0124e-01,  1.6165e-01,  1.4023e-01,\n",
      "        -3.3344e-01], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A = model.bn1.weight / torch.sqrt(model.bn1.running_var + model.bn1.eps)\n",
    "b = -(model.bn1.weight * model.bn1.running_mean / torch.sqrt(model.bn1.running_var + model.bn1.eps)) + model.bn1.bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "for i in range(16):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "    \n",
    "    for j in range(3):\n",
    "        k1 = np.append(k1, np.repeat(model.conv1.weight[i][j].reshape(9)[0].detach(), 1024))\n",
    "        k2 = np.append(k2, np.repeat(model.conv1.weight[i][j].reshape(9)[1].detach(), 1024))\n",
    "        k3 = np.append(k3, np.repeat(model.conv1.weight[i][j].reshape(9)[2].detach(), 1024))\n",
    "        k4 = np.append(k4, np.repeat(model.conv1.weight[i][j].reshape(9)[3].detach(), 1024))\n",
    "        k5 = np.append(k5, np.repeat(model.conv1.weight[i][j].reshape(9)[4].detach(), 1024))\n",
    "        k6 = np.append(k6, np.repeat(model.conv1.weight[i][j].reshape(9)[5].detach(), 1024))\n",
    "        k7 = np.append(k7, np.repeat(model.conv1.weight[i][j].reshape(9)[6].detach(), 1024))\n",
    "        k8 = np.append(k8, np.repeat(model.conv1.weight[i][j].reshape(9)[7].detach(), 1024))\n",
    "        k9 = np.append(k9, np.repeat(model.conv1.weight[i][j].reshape(9)[8].detach(), 1024))\n",
    "        \n",
    "        \n",
    "    for j in range(16 - 3):\n",
    "        k1 = np.append(k1, np.repeat(0, 1024))\n",
    "        k2 = np.append(k2, np.repeat(0, 1024))\n",
    "        k3 = np.append(k3, np.repeat(0, 1024))\n",
    "        k4 = np.append(k4, np.repeat(0, 1024))\n",
    "        k5 = np.append(k5, np.repeat(0, 1024))\n",
    "        k6 = np.append(k6, np.repeat(0, 1024))\n",
    "        k7 = np.append(k7, np.repeat(0, 1024))\n",
    "        k8 = np.append(k8, np.repeat(0, 1024))\n",
    "        k9 = np.append(k9, np.repeat(0, 1024))\n",
    "        \n",
    "        \n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "    \n",
    "    \n",
    "    k1 = np.multiply(k1, np.repeat(A[i].detach(), 16384))\n",
    "    k2 = np.multiply(k2, np.repeat(A[i].detach(), 16384))\n",
    "    k3 = np.multiply(k3, np.repeat(A[i].detach(), 16384))\n",
    "    k4 = np.multiply(k4, np.repeat(A[i].detach(), 16384))\n",
    "    k5 = np.multiply(k5, np.repeat(A[i].detach(), 16384))\n",
    "    k6 = np.multiply(k6, np.repeat(A[i].detach(), 16384))\n",
    "    k7 = np.multiply(k7, np.repeat(A[i].detach(), 16384))\n",
    "    k8 = np.multiply(k8, np.repeat(A[i].detach(), 16384))\n",
    "    k9 = np.multiply(k9, np.repeat(A[i].detach(), 16384))\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    mul1 = np.roll(k1, 1024 * i)\n",
    "    mul2 = np.roll(k2, 1024 * i)\n",
    "    mul3 = np.roll(k3, 1024 * i)\n",
    "    mul4 = np.roll(k4, 1024 * i)\n",
    "    mul5 = np.roll(k5, 1024 * i)\n",
    "    mul6 = np.roll(k6, 1024 * i)\n",
    "    mul7 = np.roll(k7, 1024 * i)\n",
    "    mul8 = np.roll(k8, 1024 * i)\n",
    "    mul9 = np.roll(k9, 1024 * i)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.savetxt('weights/conv1bn1-ch{}-k1.bin'.format(i), k1, delimiter=',')\n",
    "    np.savetxt('weights/conv1bn1-ch{}-k2.bin'.format(i), k2, delimiter=',')\n",
    "    np.savetxt('weights/conv1bn1-ch{}-k3.bin'.format(i), k3, delimiter=',')\n",
    "    np.savetxt('weights/conv1bn1-ch{}-k4.bin'.format(i), k4, delimiter=',')\n",
    "    np.savetxt('weights/conv1bn1-ch{}-k5.bin'.format(i), k5, delimiter=',')\n",
    "    np.savetxt('weights/conv1bn1-ch{}-k6.bin'.format(i), k6, delimiter=',')\n",
    "    np.savetxt('weights/conv1bn1-ch{}-k7.bin'.format(i), k7, delimiter=',')\n",
    "    np.savetxt('weights/conv1bn1-ch{}-k8.bin'.format(i), k8, delimiter=',')\n",
    "    np.savetxt('weights/conv1bn1-ch{}-k9.bin'.format(i), k9, delimiter=',')\n",
    "    \n",
    "np.savetxt('weights/conv1bn1-bias.bin'.format(i), np.repeat(b.detach(), 1024), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec8a87",
   "metadata": {},
   "source": [
    "## Layer1[0]: Conv1+Bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f40df479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([1.2913, 1.4062, 1.5185, 1.3907, 1.2287, 1.1996, 2.3732, 1.5576, 1.2722,\n",
      "        0.8757, 1.2385, 1.2919, 0.6880, 1.8140, 1.3442, 1.9891],\n",
      "       grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([ 0.1030, -0.5854,  0.2304,  0.1297,  0.6845,  0.6135, -0.9472,  0.2344,\n",
      "         0.6070,  0.5252,  0.2973,  0.2070,  0.3914, -0.2960,  0.2170,  0.9015],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A = model.layer1[0].bn1.weight / torch.sqrt(model.layer1[0].bn1.running_var + model.layer1[0].bn1.eps)\n",
    "b = -(model.layer1[0].bn1.weight * model.layer1[0].bn1.running_mean / torch.sqrt(model.layer1[0].bn1.running_var + model.layer1[0].bn1.eps)) + model.layer1[0].bn1.bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "for i in range(16):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "    \n",
    "    for j in range(16):\n",
    "        k1 = np.append(k1, np.repeat(model.layer1[0].conv1.weight[j][(j+i) % 16].reshape(9)[0].detach(), 1024))\n",
    "        k2 = np.append(k2, np.repeat(model.layer1[0].conv1.weight[j][(j+i) % 16].reshape(9)[1].detach(), 1024))\n",
    "        k3 = np.append(k3, np.repeat(model.layer1[0].conv1.weight[j][(j+i) % 16].reshape(9)[2].detach(), 1024))\n",
    "        k4 = np.append(k4, np.repeat(model.layer1[0].conv1.weight[j][(j+i) % 16].reshape(9)[3].detach(), 1024))\n",
    "        k5 = np.append(k5, np.repeat(model.layer1[0].conv1.weight[j][(j+i) % 16].reshape(9)[4].detach(), 1024))\n",
    "        k6 = np.append(k6, np.repeat(model.layer1[0].conv1.weight[j][(j+i) % 16].reshape(9)[5].detach(), 1024))\n",
    "        k7 = np.append(k7, np.repeat(model.layer1[0].conv1.weight[j][(j+i) % 16].reshape(9)[6].detach(), 1024))\n",
    "        k8 = np.append(k8, np.repeat(model.layer1[0].conv1.weight[j][(j+i) % 16].reshape(9)[7].detach(), 1024))\n",
    "        k9 = np.append(k9, np.repeat(model.layer1[0].conv1.weight[j][(j+i) % 16].reshape(9)[8].detach(), 1024))\n",
    "        \n",
    "    #The binary mask is required to put zeros in values coming from other channels and so on\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "    \n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 1024))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 1024))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 1024))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 1024))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 1024))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 1024))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 1024))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 1024))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 1024))\n",
    "\n",
    "    mul1 = np.roll(k1, 1024 * i)\n",
    "    mul2 = np.roll(k2, 1024 * i)\n",
    "    mul3 = np.roll(k3, 1024 * i)\n",
    "    mul4 = np.roll(k4, 1024 * i)\n",
    "    mul5 = np.roll(k5, 1024 * i)\n",
    "    mul6 = np.roll(k6, 1024 * i)\n",
    "    mul7 = np.roll(k7, 1024 * i)\n",
    "    mul8 = np.roll(k8, 1024 * i)\n",
    "    mul9 = np.roll(k9, 1024 * i)\n",
    "    \n",
    "    \n",
    "    np.savetxt('weights/layer1-conv1bn1-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv1bn1-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv1bn1-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv1bn1-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv1bn1-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv1bn1-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv1bn1-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv1bn1-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv1bn1-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "    \n",
    "np.savetxt('weights/layer1-conv1bn1-bias.bin'.format(i), np.repeat(b.detach(), 1024), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edccd9ea",
   "metadata": {},
   "source": [
    "## Layer1[0]: Conv2+Bn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31b11ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([1.7887, 1.8403, 1.9545, 1.4659, 2.3055, 1.2812, 2.2585, 1.7085, 1.8006,\n",
      "        1.1454, 2.3978, 1.1639, 1.8895, 1.8854, 1.6533, 2.3907],\n",
      "       grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([-0.1006,  0.3757,  0.0637,  0.2553, -0.0838,  0.1023, -0.3876,  0.2350,\n",
      "        -0.3053, -0.1146,  0.2839,  0.0036,  0.0646,  0.2457,  0.2339, -0.1216],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A = model.layer1[0].bn2.weight / torch.sqrt(model.layer1[0].bn2.running_var + model.layer1[0].bn2.eps)\n",
    "b = -(model.layer1[0].bn2.weight * model.layer1[0].bn2.running_mean / torch.sqrt(model.layer1[0].bn2.running_var + model.layer1[0].bn2.eps)) + model.layer1[0].bn2.bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "for i in range(16):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "    \n",
    "    for j in range(16):\n",
    "        k1 = np.append(k1, np.repeat(model.layer1[0].conv2.weight[j][(j+i) % 16].reshape(9)[0].detach(), 1024))\n",
    "        k2 = np.append(k2, np.repeat(model.layer1[0].conv2.weight[j][(j+i) % 16].reshape(9)[1].detach(), 1024))\n",
    "        k3 = np.append(k3, np.repeat(model.layer1[0].conv2.weight[j][(j+i) % 16].reshape(9)[2].detach(), 1024))\n",
    "        k4 = np.append(k4, np.repeat(model.layer1[0].conv2.weight[j][(j+i) % 16].reshape(9)[3].detach(), 1024))\n",
    "        k5 = np.append(k5, np.repeat(model.layer1[0].conv2.weight[j][(j+i) % 16].reshape(9)[4].detach(), 1024))\n",
    "        k6 = np.append(k6, np.repeat(model.layer1[0].conv2.weight[j][(j+i) % 16].reshape(9)[5].detach(), 1024))\n",
    "        k7 = np.append(k7, np.repeat(model.layer1[0].conv2.weight[j][(j+i) % 16].reshape(9)[6].detach(), 1024))\n",
    "        k8 = np.append(k8, np.repeat(model.layer1[0].conv2.weight[j][(j+i) % 16].reshape(9)[7].detach(), 1024))\n",
    "        k9 = np.append(k9, np.repeat(model.layer1[0].conv2.weight[j][(j+i) % 16].reshape(9)[8].detach(), 1024))\n",
    "        \n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "    \n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 1024))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 1024))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 1024))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 1024))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 1024))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 1024))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 1024))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 1024))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 1024))\n",
    "\n",
    "    mul1 = np.roll(k1, 1024 * i)\n",
    "    mul2 = np.roll(k2, 1024 * i)\n",
    "    mul3 = np.roll(k3, 1024 * i)\n",
    "    mul4 = np.roll(k4, 1024 * i)\n",
    "    mul5 = np.roll(k5, 1024 * i)\n",
    "    mul6 = np.roll(k6, 1024 * i)\n",
    "    mul7 = np.roll(k7, 1024 * i)\n",
    "    mul8 = np.roll(k8, 1024 * i)\n",
    "    mul9 = np.roll(k9, 1024 * i)\n",
    "    \n",
    "    \n",
    "    np.savetxt('weights/layer1-conv2bn2-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv2bn2-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv2bn2-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv2bn2-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv2bn2-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv2bn2-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv2bn2-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv2bn2-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer1-conv2bn2-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "    \n",
    "np.savetxt('weights/layer1-conv2bn2-bias.bin'.format(i), np.repeat(b.detach(), 1024), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff41a352",
   "metadata": {},
   "source": [
    "## Layer1[1]: Conv1+Bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c17e66d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([0.9512, 0.9473, 0.9568, 0.8786, 0.9743, 0.7121, 0.8849, 0.8243, 0.8628,\n",
      "        0.9009, 0.7942, 0.9439, 0.7756, 1.5203, 1.0352, 0.8761],\n",
      "       grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([ 0.1961,  0.4934,  0.4587,  0.0786,  0.1283,  0.1039,  0.3006,  0.4095,\n",
      "         0.4549,  0.1759,  0.1904,  0.4729,  0.1916, -0.2593, -0.1272,  0.3947],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A = model.layer1[1].bn1.weight / torch.sqrt(model.layer1[1].bn1.running_var + model.layer1[1].bn1.eps)\n",
    "b = -(model.layer1[1].bn1.weight * model.layer1[1].bn1.running_mean / torch.sqrt(model.layer1[1].bn1.running_var + model.layer1[1].bn1.eps)) + model.layer1[1].bn1.bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "for i in range(16):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "    \n",
    "    for j in range(16):\n",
    "        k1 = np.append(k1, np.repeat(model.layer1[1].conv1.weight[j][(j+i) % 16].reshape(9)[0].detach(), 1024))\n",
    "        k2 = np.append(k2, np.repeat(model.layer1[1].conv1.weight[j][(j+i) % 16].reshape(9)[1].detach(), 1024))\n",
    "        k3 = np.append(k3, np.repeat(model.layer1[1].conv1.weight[j][(j+i) % 16].reshape(9)[2].detach(), 1024))\n",
    "        k4 = np.append(k4, np.repeat(model.layer1[1].conv1.weight[j][(j+i) % 16].reshape(9)[3].detach(), 1024))\n",
    "        k5 = np.append(k5, np.repeat(model.layer1[1].conv1.weight[j][(j+i) % 16].reshape(9)[4].detach(), 1024))\n",
    "        k6 = np.append(k6, np.repeat(model.layer1[1].conv1.weight[j][(j+i) % 16].reshape(9)[5].detach(), 1024))\n",
    "        k7 = np.append(k7, np.repeat(model.layer1[1].conv1.weight[j][(j+i) % 16].reshape(9)[6].detach(), 1024))\n",
    "        k8 = np.append(k8, np.repeat(model.layer1[1].conv1.weight[j][(j+i) % 16].reshape(9)[7].detach(), 1024))\n",
    "        k9 = np.append(k9, np.repeat(model.layer1[1].conv1.weight[j][(j+i) % 16].reshape(9)[8].detach(), 1024))\n",
    "        \n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "    \n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 1024))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 1024))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 1024))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 1024))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 1024))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 1024))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 1024))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 1024))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 1024))\n",
    "\n",
    "    mul1 = np.roll(k1, 1024 * i)\n",
    "    mul2 = np.roll(k2, 1024 * i)\n",
    "    mul3 = np.roll(k3, 1024 * i)\n",
    "    mul4 = np.roll(k4, 1024 * i)\n",
    "    mul5 = np.roll(k5, 1024 * i)\n",
    "    mul6 = np.roll(k6, 1024 * i)\n",
    "    mul7 = np.roll(k7, 1024 * i)\n",
    "    mul8 = np.roll(k8, 1024 * i)\n",
    "    mul9 = np.roll(k9, 1024 * i)\n",
    "    \n",
    "    \n",
    "    np.savetxt('weights/layer2-conv1bn1-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv1bn1-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv1bn1-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv1bn1-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv1bn1-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv1bn1-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv1bn1-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv1bn1-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv1bn1-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "    \n",
    "np.savetxt('weights/layer2-conv1bn1-bias.bin'.format(i), np.repeat(b.detach(), 1024), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff34af5",
   "metadata": {},
   "source": [
    "## Layer1[1]: Conv2+Bn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7e8433a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([1.7232, 1.8680, 1.9703, 1.6121, 2.5556, 1.2564, 2.3420, 1.0104, 1.5695,\n",
      "        1.5707, 2.2538, 0.8839, 2.6276, 2.3788, 0.9073, 2.1205],\n",
      "       grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([-0.1004,  0.0595, -0.0448,  0.0679, -0.0494,  0.1123, -0.0568,  0.1378,\n",
      "        -0.0281,  0.0318,  0.1749,  0.1474,  0.2554,  0.3776,  0.0850, -0.1313],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A = model.layer1[1].bn2.weight / torch.sqrt(model.layer1[1].bn2.running_var + model.layer1[1].bn2.eps)\n",
    "b = -(model.layer1[1].bn2.weight * model.layer1[1].bn2.running_mean / torch.sqrt(model.layer1[1].bn2.running_var + model.layer1[1].bn2.eps)) + model.layer1[1].bn2.bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "for i in range(16):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "    \n",
    "    for j in range(16):\n",
    "        k1 = np.append(k1, np.repeat(model.layer1[1].conv2.weight[j][(j+i) % 16].reshape(9)[0].detach(), 1024))\n",
    "        k2 = np.append(k2, np.repeat(model.layer1[1].conv2.weight[j][(j+i) % 16].reshape(9)[1].detach(), 1024))\n",
    "        k3 = np.append(k3, np.repeat(model.layer1[1].conv2.weight[j][(j+i) % 16].reshape(9)[2].detach(), 1024))\n",
    "        k4 = np.append(k4, np.repeat(model.layer1[1].conv2.weight[j][(j+i) % 16].reshape(9)[3].detach(), 1024))\n",
    "        k5 = np.append(k5, np.repeat(model.layer1[1].conv2.weight[j][(j+i) % 16].reshape(9)[4].detach(), 1024))\n",
    "        k6 = np.append(k6, np.repeat(model.layer1[1].conv2.weight[j][(j+i) % 16].reshape(9)[5].detach(), 1024))\n",
    "        k7 = np.append(k7, np.repeat(model.layer1[1].conv2.weight[j][(j+i) % 16].reshape(9)[6].detach(), 1024))\n",
    "        k8 = np.append(k8, np.repeat(model.layer1[1].conv2.weight[j][(j+i) % 16].reshape(9)[7].detach(), 1024))\n",
    "        k9 = np.append(k9, np.repeat(model.layer1[1].conv2.weight[j][(j+i) % 16].reshape(9)[8].detach(), 1024))\n",
    "        \n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "    \n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 1024))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 1024))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 1024))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 1024))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 1024))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 1024))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 1024))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 1024))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 1024))\n",
    "\n",
    "    mul1 = np.roll(k1, 1024 * i)\n",
    "    mul2 = np.roll(k2, 1024 * i)\n",
    "    mul3 = np.roll(k3, 1024 * i)\n",
    "    mul4 = np.roll(k4, 1024 * i)\n",
    "    mul5 = np.roll(k5, 1024 * i)\n",
    "    mul6 = np.roll(k6, 1024 * i)\n",
    "    mul7 = np.roll(k7, 1024 * i)\n",
    "    mul8 = np.roll(k8, 1024 * i)\n",
    "    mul9 = np.roll(k9, 1024 * i)\n",
    "    \n",
    "    \n",
    "    np.savetxt('weights/layer2-conv2bn2-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv2bn2-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv2bn2-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv2bn2-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv2bn2-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv2bn2-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv2bn2-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv2bn2-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer2-conv2bn2-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "    \n",
    "np.savetxt('weights/layer2-conv2bn2-bias.bin'.format(i), np.repeat(b.detach(), 1024), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f9770",
   "metadata": {},
   "source": [
    "## Layer1[2]: Conv1+Bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85ec4700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([0.4727, 0.6169, 0.6216, 0.6147, 0.5112, 0.4841, 0.6642, 0.9769, 0.6833,\n",
      "        0.7435, 0.5036, 1.4373, 0.5373, 0.7193, 0.4917, 0.5333],\n",
      "       grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([ 0.0948, -0.0024,  0.1346,  0.3193, -0.0341, -0.0317,  0.0181, -0.0961,\n",
      "         0.2751,  0.0100, -0.0352,  0.2013,  0.0923,  0.1866, -0.0487, -0.1360],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A = model.layer1[2].bn1.weight / torch.sqrt(model.layer1[2].bn1.running_var + model.layer1[2].bn1.eps)\n",
    "b = -(model.layer1[2].bn1.weight * model.layer1[2].bn1.running_mean / torch.sqrt(model.layer1[2].bn1.running_var + model.layer1[2].bn1.eps)) + model.layer1[2].bn1.bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "for i in range(16):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "    \n",
    "    for j in range(16):\n",
    "        k1 = np.append(k1, np.repeat(model.layer1[2].conv1.weight[j][(j+i) % 16].reshape(9)[0].detach(), 1024))\n",
    "        k2 = np.append(k2, np.repeat(model.layer1[2].conv1.weight[j][(j+i) % 16].reshape(9)[1].detach(), 1024))\n",
    "        k3 = np.append(k3, np.repeat(model.layer1[2].conv1.weight[j][(j+i) % 16].reshape(9)[2].detach(), 1024))\n",
    "        k4 = np.append(k4, np.repeat(model.layer1[2].conv1.weight[j][(j+i) % 16].reshape(9)[3].detach(), 1024))\n",
    "        k5 = np.append(k5, np.repeat(model.layer1[2].conv1.weight[j][(j+i) % 16].reshape(9)[4].detach(), 1024))\n",
    "        k6 = np.append(k6, np.repeat(model.layer1[2].conv1.weight[j][(j+i) % 16].reshape(9)[5].detach(), 1024))\n",
    "        k7 = np.append(k7, np.repeat(model.layer1[2].conv1.weight[j][(j+i) % 16].reshape(9)[6].detach(), 1024))\n",
    "        k8 = np.append(k8, np.repeat(model.layer1[2].conv1.weight[j][(j+i) % 16].reshape(9)[7].detach(), 1024))\n",
    "        k9 = np.append(k9, np.repeat(model.layer1[2].conv1.weight[j][(j+i) % 16].reshape(9)[8].detach(), 1024))\n",
    "        \n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "    \n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 1024))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 1024))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 1024))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 1024))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 1024))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 1024))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 1024))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 1024))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 1024))\n",
    "\n",
    "    mul1 = np.roll(k1, 1024 * i)\n",
    "    mul2 = np.roll(k2, 1024 * i)\n",
    "    mul3 = np.roll(k3, 1024 * i)\n",
    "    mul4 = np.roll(k4, 1024 * i)\n",
    "    mul5 = np.roll(k5, 1024 * i)\n",
    "    mul6 = np.roll(k6, 1024 * i)\n",
    "    mul7 = np.roll(k7, 1024 * i)\n",
    "    mul8 = np.roll(k8, 1024 * i)\n",
    "    mul9 = np.roll(k9, 1024 * i)\n",
    "    \n",
    "    \n",
    "    np.savetxt('weights/layer3-conv1bn1-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv1bn1-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv1bn1-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv1bn1-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv1bn1-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv1bn1-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv1bn1-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv1bn1-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv1bn1-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "    \n",
    "np.savetxt('weights/layer3-conv1bn1-bias.bin'.format(i), np.repeat(b.detach(), 1024), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9bf46b",
   "metadata": {},
   "source": [
    "## Layer1[2]: Conv2+Bn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3b537d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([1.4420, 2.3079, 2.0004, 1.8164, 3.1310, 1.0375, 1.6597, 1.2105, 1.5634,\n",
      "        1.9707, 2.7410, 0.9834, 3.0938, 2.3891, 1.0242, 1.6197],\n",
      "       grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([-0.0065, -0.3248, -0.2871,  0.1492, -0.2957,  0.0458, -0.0024,  0.0452,\n",
      "         0.3127, -0.1194,  0.1744,  0.0773,  0.3441,  0.1627,  0.0258, -0.1078],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A = model.layer1[2].bn2.weight / torch.sqrt(model.layer1[2].bn2.running_var + model.layer1[2].bn2.eps)\n",
    "b = -(model.layer1[2].bn2.weight * model.layer1[2].bn2.running_mean / torch.sqrt(model.layer1[2].bn2.running_var + model.layer1[2].bn2.eps)) + model.layer1[2].bn2.bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "for i in range(16):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "    \n",
    "    for j in range(16):\n",
    "        k1 = np.append(k1, np.repeat(model.layer1[2].conv2.weight[j][(j+i) % 16].reshape(9)[0].detach(), 1024))\n",
    "        k2 = np.append(k2, np.repeat(model.layer1[2].conv2.weight[j][(j+i) % 16].reshape(9)[1].detach(), 1024))\n",
    "        k3 = np.append(k3, np.repeat(model.layer1[2].conv2.weight[j][(j+i) % 16].reshape(9)[2].detach(), 1024))\n",
    "        k4 = np.append(k4, np.repeat(model.layer1[2].conv2.weight[j][(j+i) % 16].reshape(9)[3].detach(), 1024))\n",
    "        k5 = np.append(k5, np.repeat(model.layer1[2].conv2.weight[j][(j+i) % 16].reshape(9)[4].detach(), 1024))\n",
    "        k6 = np.append(k6, np.repeat(model.layer1[2].conv2.weight[j][(j+i) % 16].reshape(9)[5].detach(), 1024))\n",
    "        k7 = np.append(k7, np.repeat(model.layer1[2].conv2.weight[j][(j+i) % 16].reshape(9)[6].detach(), 1024))\n",
    "        k8 = np.append(k8, np.repeat(model.layer1[2].conv2.weight[j][(j+i) % 16].reshape(9)[7].detach(), 1024))\n",
    "        k9 = np.append(k9, np.repeat(model.layer1[2].conv2.weight[j][(j+i) % 16].reshape(9)[8].detach(), 1024))\n",
    "        \n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "    \n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 1024))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 1024))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 1024))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 1024))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 1024))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 1024))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 1024))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 1024))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 1024))\n",
    "\n",
    "    mul1 = np.roll(k1, 1024 * i)\n",
    "    mul2 = np.roll(k2, 1024 * i)\n",
    "    mul3 = np.roll(k3, 1024 * i)\n",
    "    mul4 = np.roll(k4, 1024 * i)\n",
    "    mul5 = np.roll(k5, 1024 * i)\n",
    "    mul6 = np.roll(k6, 1024 * i)\n",
    "    mul7 = np.roll(k7, 1024 * i)\n",
    "    mul8 = np.roll(k8, 1024 * i)\n",
    "    mul9 = np.roll(k9, 1024 * i)\n",
    "    \n",
    "    \n",
    "    np.savetxt('weights/layer3-conv2bn2-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv2bn2-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv2bn2-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv2bn2-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv2bn2-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv2bn2-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv2bn2-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv2bn2-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer3-conv2bn2-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "    \n",
    "np.savetxt('weights/layer3-conv2bn2-bias.bin'.format(i), np.repeat(b.detach(), 1024), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2796bcf",
   "metadata": {},
   "source": [
    "## Layer2[0]: Conv1+Bn1 SX DownsamplingFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a9f6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dispari sempre 0, riempe i primi 32 mod 64\n",
    "def altalena(v):\n",
    "    new_v = []\n",
    "    for i in range(len(v)):\n",
    "        if i % 2 != 0:\n",
    "            new_v.append(0)\n",
    "        elif i % 64 >= 32 and i % 64 < 64:\n",
    "            new_v.append(0)\n",
    "        else:\n",
    "            new_v.append(v[i])\n",
    "    return new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f6d9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con singola rotazione\n",
    "\n",
    "A = model.layer2[0].bn1.weight / torch.sqrt(model.layer2[0].bn1.running_var + model.layer2[0].bn1.eps)\n",
    "b = -(model.layer2[0].bn1.weight * model.layer2[0].bn1.running_mean / torch.sqrt(model.layer2[0].bn1.running_var + model.layer2[0].bn1.eps)) + model.layer2[0].bn1.bias\n",
    "\n",
    "for i in range(16):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "    \n",
    "    for j in range(32):\n",
    "        k1 = np.append(k1, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[0].detach(), 1024))\n",
    "        k2 = np.append(k2, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[1].detach(), 1024))\n",
    "        k3 = np.append(k3, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[2].detach(), 1024))\n",
    "        k4 = np.append(k4, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[3].detach(), 1024))\n",
    "        k5 = np.append(k5, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[4].detach(), 1024))\n",
    "        k6 = np.append(k6, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[5].detach(), 1024))\n",
    "        k7 = np.append(k7, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[6].detach(), 1024))\n",
    "        k8 = np.append(k8, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[7].detach(), 1024))\n",
    "        k9 = np.append(k9, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[8].detach(), 1024))\n",
    "    \n",
    "    \n",
    "    k1 = np.multiply(k1, altalena(np.tile(bin_mask1, 2)))\n",
    "    k2 = np.multiply(k2, altalena(np.tile(bin_mask2, 2)))\n",
    "    k3 = np.multiply(k3, altalena(np.tile(bin_mask3, 2)))\n",
    "    k4 = np.multiply(k4, altalena(np.tile(bin_mask4, 2)))\n",
    "    k5 = np.multiply(k5, altalena(np.tile(bin_mask5, 2)))\n",
    "    k6 = np.multiply(k6, altalena(np.tile(bin_mask6, 2)))\n",
    "    k7 = np.multiply(k7, altalena(np.tile(bin_mask7, 2)))\n",
    "    k8 = np.multiply(k8, altalena(np.tile(bin_mask8, 2)))\n",
    "    k9 = np.multiply(k9, altalena(np.tile(bin_mask9, 2)))\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach().numpy(), 1024))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach().numpy(), 1024))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach().numpy(), 1024))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach().numpy(), 1024))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach().numpy(), 1024))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach().numpy(), 1024))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach().numpy(), 1024))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach().numpy(), 1024))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach().numpy(), 1024))\n",
    "    \n",
    "    \n",
    "    #Affianco CH1[0]-CH16[0]-CH1[1]-CH16[1]-CH1[2]...\n",
    "    k1 = np.add(k1, np.roll(k1, -16384 + 1))[:16384]\n",
    "    k2 = np.add(k2, np.roll(k2, -16384 + 1))[:16384]\n",
    "    k3 = np.add(k3, np.roll(k3, -16384 + 1))[:16384]\n",
    "    k4 = np.add(k4, np.roll(k4, -16384 + 1))[:16384]\n",
    "    k5 = np.add(k5, np.roll(k5, -16384 + 1))[:16384]\n",
    "    k6 = np.add(k6, np.roll(k6, -16384 + 1))[:16384]\n",
    "    k7 = np.add(k7, np.roll(k7, -16384 + 1))[:16384]\n",
    "    k8 = np.add(k8, np.roll(k8, -16384 + 1))[:16384]\n",
    "    k9 = np.add(k9, np.roll(k9, -16384 + 1))[:16384]\n",
    "\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k1.bin'.format(i), altalena(np.roll(k1, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k2.bin'.format(i), altalena(np.roll(k2, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k3.bin'.format(i), altalena(np.roll(k3, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k4.bin'.format(i), altalena(np.roll(k4, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k5.bin'.format(i), altalena(np.roll(k5, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k6.bin'.format(i), altalena(np.roll(k6, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k7.bin'.format(i), altalena(np.roll(k7, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k8.bin'.format(i), altalena(np.roll(k8, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k9.bin'.format(i), altalena(np.roll(k9, 1024 * i)), delimiter=',')\n",
    "    \n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k1.bin'.format(i+16), altalena(np.roll(k1, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k2.bin'.format(i+16), altalena(np.roll(k2, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k3.bin'.format(i+16), altalena(np.roll(k3, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k4.bin'.format(i+16), altalena(np.roll(k4, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k5.bin'.format(i+16), altalena(np.roll(k5, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k6.bin'.format(i+16), altalena(np.roll(k6, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k7.bin'.format(i+16), altalena(np.roll(k7, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k8.bin'.format(i+16), altalena(np.roll(k8, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k9.bin'.format(i+16), altalena(np.roll(k9, 1024 * i - 1)), delimiter=',')\n",
    "\n",
    "bias_corrected = np.add(altalena(np.repeat(b.detach().numpy(),1024)), np.roll(altalena(np.repeat(b.detach().numpy(),1024)), -16384 + 1))[:16384]\n",
    "bias_corrected016 = altalena(np.repeat(b.detach().numpy()[:16], 1024))\n",
    "bias_corrected1632 = altalena(np.roll(np.repeat(b.detach().numpy()[16:32], 1024), -1))\n",
    "\n",
    "np.savetxt('weights/layer4-conv1bn1-bias1.bin', bias_corrected016, delimiter=',')\n",
    "np.savetxt('weights/layer4-conv1bn1-bias2.bin', bias_corrected1632, delimiter=',')\n",
    "\n",
    "#N.b il 1632 deve essere ruotato a DX di uno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4aaf3",
   "metadata": {},
   "source": [
    "##Layer2[0]: Conv1+Bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9698589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([0.8141, 0.6018, 0.8376, 0.6278, 0.8170, 0.6266, 0.6413, 1.0384, 0.7254,\n",
      "        0.7201, 0.7055, 0.4483, 0.5056, 0.6135, 0.7686, 0.8012, 0.8914, 0.6620,\n",
      "        0.7178, 0.7898, 0.4978, 0.8644, 0.5556, 0.5686, 0.8200, 0.8590, 0.8207,\n",
      "        0.9914, 0.6215, 0.6291, 0.6780, 0.9323], grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([-0.2723,  0.4193,  0.3852,  0.1376, -0.2815, -0.4210, -0.0659,  0.0707,\n",
      "        -0.8956,  0.2584, -0.5191,  0.2679, -0.0894,  0.3139,  0.1139,  0.8343,\n",
      "        -0.2597,  0.1324, -0.2290,  0.2976,  0.6561, -0.0629,  0.3382,  0.2354,\n",
      "        -0.1413,  0.1835, -0.1575, -0.3741,  0.4320,  0.0388,  0.2430, -0.3959],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A = model.layer2[0].bn1.weight / torch.sqrt(model.layer2[0].bn1.running_var + model.layer2[0].bn1.eps)\n",
    "b = -(model.layer2[0].bn1.weight * model.layer2[0].bn1.running_mean / torch.sqrt(model.layer2[0].bn1.running_var + model.layer2[0].bn1.eps)) + model.layer2[0].bn1.bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "channels = []\n",
    "\n",
    "for i in range(16):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "    \n",
    "    for j in range(32):\n",
    "        k1 = np.append(k1, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[0].detach(), 1024))\n",
    "        k2 = np.append(k2, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[1].detach(), 1024))\n",
    "        k3 = np.append(k3, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[2].detach(), 1024))\n",
    "        k4 = np.append(k4, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[3].detach(), 1024))\n",
    "        k5 = np.append(k5, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[4].detach(), 1024))\n",
    "        k6 = np.append(k6, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[5].detach(), 1024))\n",
    "        k7 = np.append(k7, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[6].detach(), 1024))\n",
    "        k8 = np.append(k8, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[7].detach(), 1024))\n",
    "        k9 = np.append(k9, np.repeat(model.layer2[0].conv1.weight[j][(j+i) % 16].reshape(9)[8].detach(), 1024))\n",
    "    \n",
    "    k1 = np.multiply(k1, altalena(np.tile(bin_mask1, 2)))\n",
    "    k2 = np.multiply(k2, altalena(np.tile(bin_mask2, 2)))\n",
    "    k3 = np.multiply(k3, altalena(np.tile(bin_mask3, 2)))\n",
    "    k4 = np.multiply(k4, altalena(np.tile(bin_mask4, 2)))\n",
    "    k5 = np.multiply(k5, altalena(np.tile(bin_mask5, 2)))\n",
    "    k6 = np.multiply(k6, altalena(np.tile(bin_mask6, 2)))\n",
    "    k7 = np.multiply(k7, altalena(np.tile(bin_mask7, 2)))\n",
    "    k8 = np.multiply(k8, altalena(np.tile(bin_mask8, 2)))\n",
    "    k9 = np.multiply(k9, altalena(np.tile(bin_mask9, 2)))\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach().numpy(), 1024))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach().numpy(), 1024))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach().numpy(), 1024))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach().numpy(), 1024))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach().numpy(), 1024))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach().numpy(), 1024))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach().numpy(), 1024))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach().numpy(), 1024))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach().numpy(), 1024))\n",
    "\n",
    "    \n",
    "    #Affianco CH1[0]-CH16[0]-CH1[1]-CH16[1]-CH1[2]...\n",
    "    k1 = np.add(k1, np.roll(k1, -16384 + 1))[:16384]\n",
    "    k2 = np.add(k2, np.roll(k2, -16384 + 1))[:16384]\n",
    "    k3 = np.add(k3, np.roll(k3, -16384 + 1))[:16384]\n",
    "    k4 = np.add(k4, np.roll(k4, -16384 + 1))[:16384]\n",
    "    k5 = np.add(k5, np.roll(k5, -16384 + 1))[:16384]\n",
    "    k6 = np.add(k6, np.roll(k6, -16384 + 1))[:16384]\n",
    "    k7 = np.add(k7, np.roll(k7, -16384 + 1))[:16384]\n",
    "    k8 = np.add(k8, np.roll(k8, -16384 + 1))[:16384]\n",
    "    k9 = np.add(k9, np.roll(k9, -16384 + 1))[:16384]\n",
    "\n",
    "    \n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k1.bin'.format(i), altalena(np.roll(k1, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k1.bin'.format(i+16), altalena(np.roll(k1, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k2.bin'.format(i), altalena(np.roll(k2, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k2.bin'.format(i+16), altalena(np.roll(k2, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k3.bin'.format(i), altalena(np.roll(k3, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k3.bin'.format(i+16), altalena(np.roll(k3, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k4.bin'.format(i), altalena(np.roll(k4, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k4.bin'.format(i+16), altalena(np.roll(k4, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k5.bin'.format(i), altalena(np.roll(k5, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k5.bin'.format(i+16), altalena(np.roll(k5, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k6.bin'.format(i), altalena(np.roll(k6, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k6.bin'.format(i+16), altalena(np.roll(k6, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k7.bin'.format(i), altalena(np.roll(k7, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k7.bin'.format(i+16), altalena(np.roll(k7, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k8.bin'.format(i), altalena(np.roll(k8, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k8.bin'.format(i+16), altalena(np.roll(k8, 1024 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k9.bin'.format(i), altalena(np.roll(k9, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv1bn1-ch{}-k9.bin'.format(i+16), altalena(np.roll(k9, 1024 * i - 1)), delimiter=',')\n",
    "    \n",
    "    \n",
    "bias_corrected = np.add(altalena(np.repeat(b.detach().numpy(),1024)), np.roll(altalena(np.repeat(b.detach().numpy(),1024)), -16384 + 1))[:16384]\n",
    "bias_corrected016 = altalena(np.repeat(b.detach().numpy()[:16], 1024))\n",
    "bias_corrected1632 = altalena(np.repeat(b.detach().numpy()[16:32], 1024))\n",
    "\n",
    "np.savetxt('weights/layer4-conv1bn1-bias1.bin'.format(i), bias_corrected016, delimiter=',')\n",
    "np.savetxt('weights/layer4-conv1bn1-bias2.bin'.format(i), bias_corrected1632, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd467bd",
   "metadata": {},
   "source": [
    "## Layer2[0]: Conv1+Bn1 DX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e505bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([1.6594, 1.0308, 1.2125, 1.3979, 1.4946, 1.1669, 0.9063, 1.0715, 1.4008,\n",
      "        1.4876, 1.2260, 0.6966, 1.4486, 1.2567, 1.2241, 1.3491, 1.3268, 0.9128,\n",
      "        1.1587, 1.1738, 1.6666, 1.2284, 0.9154, 0.8671, 1.3171, 1.2489, 0.8858,\n",
      "        1.1073, 1.3800, 0.9875, 0.7897, 1.3719], grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([-0.3772,  0.3567, -0.2218,  0.0857, -0.1227,  0.3010, -0.1443,  0.0978,\n",
      "         0.0103, -0.1659,  0.2356,  0.0668, -0.0912, -0.3083, -0.2250,  0.1427,\n",
      "        -0.1723, -0.0055,  0.0505,  0.4404, -0.0018, -0.1341,  0.4309,  0.0110,\n",
      "         0.0985,  0.3431,  0.0982,  0.4294, -0.0392, -0.0426, -0.0612, -0.0200],\n",
      "       grad_fn=<AddBackward0>)\n",
      "0.05225483749636339\n",
      "0.02010823338312462\n",
      "0.17328202992647768\n",
      "0.34971032783107603\n",
      "0.10023729103920065\n",
      "0.08835127783088126\n",
      "0.12291725034051737\n",
      "0.10110638386563231\n",
      "-0.066929951827702\n",
      "0.07851494665516423\n",
      "-0.0862680785652774\n",
      "-0.004445228822175962\n",
      "-0.03972815183723721\n",
      "0.15218021798123793\n",
      "-0.18105619819658791\n",
      "-0.08752643368645341\n"
     ]
    }
   ],
   "source": [
    "A = model.layer2[0].downsample[1].weight / torch.sqrt(model.layer2[0].downsample[1].running_var + model.layer2[0].downsample[1].eps)\n",
    "b = -(model.layer2[0].downsample[1].weight * model.layer2[0].downsample[1].running_mean / torch.sqrt(model.layer2[0].downsample[1].running_var + model.layer2[0].downsample[1].eps)) + model.layer2[0].downsample[1].bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "for i in range(16):\n",
    "    k1 = np.array([])\n",
    "    \n",
    "    for j in range(32):\n",
    "        k1 = np.append(k1, np.repeat(model.layer2[0].downsample[0].weight[j][(j+i) % 16].reshape(1)[0].detach(), 1024))\n",
    "    \n",
    "    k1 = np.multiply(k1, altalena(np.tile(bin_mask5, 2)))\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach().numpy(), 1024))\n",
    "    \n",
    "    #Affianco CH1[0]-CH16[0]-CH1[1]-CH16[1]-CH1[2]...\n",
    "    k1 = np.add(k1, np.roll(k1, -16384 + 1))[:16384]\n",
    "    \n",
    "    print(k1[0])\n",
    "\n",
    "    np.savetxt('weights/layer4dx-conv1bn1-ch{}-k1.bin'.format(i), altalena(np.roll(k1, 1024 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer4dx-conv1bn1-ch{}-k1.bin'.format(i+16), altalena(np.roll(k1, 1024 * i - 1)), delimiter=',')\n",
    "    \n",
    "bias_corrected016 = altalena(np.repeat(b.detach().numpy()[:16], 1024))\n",
    "bias_corrected1632 = altalena(np.repeat(b.detach().numpy()[16:32], 1024))\n",
    "#bias_corrected = np.add(altalena(np.repeat(b.detach().numpy(),1024)), np.roll(altalena(np.repeat(b.detach().numpy(),1024)), -16384 + 1))[:16384]\n",
    "#bias_corrected016 = altalena(np.repeat(b.detach().numpy()[:16], 1024))\n",
    "#bias_corrected1632 = altalena(np.repeat(b.detach().numpy()[16:32], 1024))\n",
    "\n",
    "np.savetxt('weights/layer4dx-conv1bn1-bias1.bin'.format(i), bias_corrected016, delimiter=',')\n",
    "np.savetxt('weights/layer4dx-conv1bn1-bias2.bin'.format(i), bias_corrected1632, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4991702a",
   "metadata": {},
   "source": [
    "## Layer2[0]: Conv2+Bn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e355bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 16\n",
    "padding = 1\n",
    "\n",
    "bin_mask1 = np.tile(np.array(build_mask(img_width + 1, 0, img_width -1, img_width ** 2)), 32)\n",
    "bin_mask2 = np.tile(np.array(build_mask(img_width, 0, img_width ** 2, img_width ** 2)), 32)\n",
    "bin_mask3 = np.tile(np.array(build_mask(img_width, 0, img_width - 1, img_width ** 2)), 32)\n",
    "bin_mask4 = np.tile(np.array(build_mask(1, 0, img_width - 1, img_width ** 2)), 32)\n",
    "bin_mask5 = np.tile(np.array(build_mask(0, 0, img_width ** 2, img_width ** 2)), 32)\n",
    "bin_mask6 = np.tile(np.array(build_mask(0, 1, img_width - 1, img_width ** 2)), 32)\n",
    "bin_mask7 = np.tile(np.array(build_mask(1, img_width - 1, img_width - 1, img_width ** 2)), 32)\n",
    "bin_mask8 = np.tile(np.array(build_mask(0, img_width, img_width ** 2, img_width ** 2)), 32)\n",
    "bin_mask9 = np.tile(np.array(build_mask(0, img_width + 1, img_width - 1, img_width ** 2)), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06210a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.layer2[0].bn2.weight / torch.sqrt(model.layer2[0].bn2.running_var + model.layer2[0].bn2.eps)\n",
    "b = -(model.layer2[0].bn2.weight * model.layer2[0].bn2.running_mean / torch.sqrt(model.layer2[0].bn2.running_var + model.layer2[0].bn2.eps)) + model.layer2[0].bn2.bias\n",
    "\n",
    "ks = []\n",
    "\n",
    "for i in range(32):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "\n",
    "    for j in range(32):\n",
    "        #Qua moltiplico np.repeat blabla per A[j]\n",
    "        k1 = np.append(k1, np.repeat(model.layer2[0].conv2.weight[j][(j+i) % 32].reshape(9)[0].detach(), 256))\n",
    "        k2 = np.append(k2, np.repeat(model.layer2[0].conv2.weight[j][(j+i) % 32].reshape(9)[1].detach(), 256))\n",
    "        k3 = np.append(k3, np.repeat(model.layer2[0].conv2.weight[j][(j+i) % 32].reshape(9)[2].detach(), 256))\n",
    "        k4 = np.append(k4, np.repeat(model.layer2[0].conv2.weight[j][(j+i) % 32].reshape(9)[3].detach(), 256))\n",
    "        k5 = np.append(k5, np.repeat(model.layer2[0].conv2.weight[j][(j+i) % 32].reshape(9)[4].detach(), 256))\n",
    "        k6 = np.append(k6, np.repeat(model.layer2[0].conv2.weight[j][(j+i) % 32].reshape(9)[5].detach(), 256))\n",
    "        k7 = np.append(k7, np.repeat(model.layer2[0].conv2.weight[j][(j+i) % 32].reshape(9)[6].detach(), 256))\n",
    "        k8 = np.append(k8, np.repeat(model.layer2[0].conv2.weight[j][(j+i) % 32].reshape(9)[7].detach(), 256))\n",
    "        k9 = np.append(k9, np.repeat(model.layer2[0].conv2.weight[j][(j+i) % 32].reshape(9)[8].detach(), 256))\n",
    "\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 256))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 256))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 256))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 256))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 256))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 256))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 256))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 256))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 256))\n",
    "    \n",
    "    mul1 = np.roll(k1, 256 * i)\n",
    "    mul2 = np.roll(k2, 256 * i)\n",
    "    mul3 = np.roll(k3, 256 * i)\n",
    "    mul4 = np.roll(k4, 256 * i)\n",
    "    mul5 = np.roll(k5, 256 * i)\n",
    "    mul6 = np.roll(k6, 256 * i)\n",
    "    mul7 = np.roll(k7, 256 * i)\n",
    "    mul8 = np.roll(k8, 256 * i)\n",
    "    mul9 = np.roll(k9, 256 * i)\n",
    "    \n",
    "    np.savetxt('weights/layer4-conv2bn2-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv2bn2-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv2bn2-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv2bn2-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv2bn2-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv2bn2-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv2bn2-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv2bn2-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer4-conv2bn2-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "\n",
    "np.savetxt('weights/layer4-conv2bn2-bias.bin', np.repeat(b.detach(), 256), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90fef3",
   "metadata": {},
   "source": [
    "## Layer2[1]: Conv1+Bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e6506fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.layer2[1].bn1.weight / torch.sqrt(model.layer2[1].bn1.running_var + model.layer2[1].bn1.eps)\n",
    "b = -(model.layer2[1].bn1.weight * model.layer2[1].bn1.running_mean / torch.sqrt(model.layer2[1].bn1.running_var + model.layer2[1].bn1.eps)) + model.layer2[1].bn1.bias\n",
    "\n",
    "ks = []\n",
    "\n",
    "for i in range(32):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "\n",
    "    for j in range(32):\n",
    "        #Qua moltiplico np.repeat blabla per A[j]\n",
    "        k1 = np.append(k1, np.repeat(model.layer2[1].conv1.weight[j][(j+i) % 32].reshape(9)[0].detach(), 256))\n",
    "        k2 = np.append(k2, np.repeat(model.layer2[1].conv1.weight[j][(j+i) % 32].reshape(9)[1].detach(), 256))\n",
    "        k3 = np.append(k3, np.repeat(model.layer2[1].conv1.weight[j][(j+i) % 32].reshape(9)[2].detach(), 256))\n",
    "        k4 = np.append(k4, np.repeat(model.layer2[1].conv1.weight[j][(j+i) % 32].reshape(9)[3].detach(), 256))\n",
    "        k5 = np.append(k5, np.repeat(model.layer2[1].conv1.weight[j][(j+i) % 32].reshape(9)[4].detach(), 256))\n",
    "        k6 = np.append(k6, np.repeat(model.layer2[1].conv1.weight[j][(j+i) % 32].reshape(9)[5].detach(), 256))\n",
    "        k7 = np.append(k7, np.repeat(model.layer2[1].conv1.weight[j][(j+i) % 32].reshape(9)[6].detach(), 256))\n",
    "        k8 = np.append(k8, np.repeat(model.layer2[1].conv1.weight[j][(j+i) % 32].reshape(9)[7].detach(), 256))\n",
    "        k9 = np.append(k9, np.repeat(model.layer2[1].conv1.weight[j][(j+i) % 32].reshape(9)[8].detach(), 256))\n",
    "\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 256))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 256))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 256))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 256))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 256))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 256))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 256))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 256))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 256))\n",
    "    \n",
    "    mul1 = np.roll(k1, 256 * i)\n",
    "    mul2 = np.roll(k2, 256 * i)\n",
    "    mul3 = np.roll(k3, 256 * i)\n",
    "    mul4 = np.roll(k4, 256 * i)\n",
    "    mul5 = np.roll(k5, 256 * i)\n",
    "    mul6 = np.roll(k6, 256 * i)\n",
    "    mul7 = np.roll(k7, 256 * i)\n",
    "    mul8 = np.roll(k8, 256 * i)\n",
    "    mul9 = np.roll(k9, 256 * i)\n",
    "    \n",
    "    np.savetxt('weights/layer5-conv1bn1-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv1bn1-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv1bn1-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv1bn1-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv1bn1-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv1bn1-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv1bn1-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv1bn1-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv1bn1-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "\n",
    "np.savetxt('weights/layer5-conv1bn1-bias.bin', np.repeat(b.detach(), 256), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a77757",
   "metadata": {},
   "source": [
    "## Layer2[1]: Conv2+Bn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af69961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.layer2[1].bn2.weight / torch.sqrt(model.layer2[1].bn2.running_var + model.layer2[1].bn2.eps)\n",
    "b = -(model.layer2[1].bn2.weight * model.layer2[1].bn2.running_mean / torch.sqrt(model.layer2[1].bn2.running_var + model.layer2[1].bn2.eps)) + model.layer2[1].bn2.bias\n",
    "\n",
    "ks = []\n",
    "\n",
    "for i in range(32):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "\n",
    "    for j in range(32):\n",
    "        #Qua moltiplico np.repeat blabla per A[j]\n",
    "        k1 = np.append(k1, np.repeat(model.layer2[1].conv2.weight[j][(j+i) % 32].reshape(9)[0].detach(), 256))\n",
    "        k2 = np.append(k2, np.repeat(model.layer2[1].conv2.weight[j][(j+i) % 32].reshape(9)[1].detach(), 256))\n",
    "        k3 = np.append(k3, np.repeat(model.layer2[1].conv2.weight[j][(j+i) % 32].reshape(9)[2].detach(), 256))\n",
    "        k4 = np.append(k4, np.repeat(model.layer2[1].conv2.weight[j][(j+i) % 32].reshape(9)[3].detach(), 256))\n",
    "        k5 = np.append(k5, np.repeat(model.layer2[1].conv2.weight[j][(j+i) % 32].reshape(9)[4].detach(), 256))\n",
    "        k6 = np.append(k6, np.repeat(model.layer2[1].conv2.weight[j][(j+i) % 32].reshape(9)[5].detach(), 256))\n",
    "        k7 = np.append(k7, np.repeat(model.layer2[1].conv2.weight[j][(j+i) % 32].reshape(9)[6].detach(), 256))\n",
    "        k8 = np.append(k8, np.repeat(model.layer2[1].conv2.weight[j][(j+i) % 32].reshape(9)[7].detach(), 256))\n",
    "        k9 = np.append(k9, np.repeat(model.layer2[1].conv2.weight[j][(j+i) % 32].reshape(9)[8].detach(), 256))\n",
    "\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 256))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 256))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 256))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 256))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 256))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 256))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 256))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 256))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 256))\n",
    "    \n",
    "    mul1 = np.roll(k1, 256 * i)\n",
    "    mul2 = np.roll(k2, 256 * i)\n",
    "    mul3 = np.roll(k3, 256 * i)\n",
    "    mul4 = np.roll(k4, 256 * i)\n",
    "    mul5 = np.roll(k5, 256 * i)\n",
    "    mul6 = np.roll(k6, 256 * i)\n",
    "    mul7 = np.roll(k7, 256 * i)\n",
    "    mul8 = np.roll(k8, 256 * i)\n",
    "    mul9 = np.roll(k9, 256 * i)\n",
    "    \n",
    "    np.savetxt('weights/layer5-conv2bn2-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv2bn2-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv2bn2-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv2bn2-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv2bn2-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv2bn2-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv2bn2-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv2bn2-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer5-conv2bn2-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "\n",
    "np.savetxt('weights/layer5-conv2bn2-bias.bin', np.repeat(b.detach(), 256), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3c8c0",
   "metadata": {},
   "source": [
    "## Layer2[2]: Conv1+Bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca49d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.layer2[2].bn1.weight / torch.sqrt(model.layer2[2].bn1.running_var + model.layer2[2].bn1.eps)\n",
    "b = -(model.layer2[2].bn1.weight * model.layer2[2].bn1.running_mean / torch.sqrt(model.layer2[2].bn1.running_var + model.layer2[2].bn1.eps)) + model.layer2[2].bn1.bias\n",
    "\n",
    "ks = []\n",
    "\n",
    "for i in range(32):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "\n",
    "    for j in range(32):\n",
    "        #Qua moltiplico np.repeat blabla per A[j]\n",
    "        k1 = np.append(k1, np.repeat(model.layer2[2].conv1.weight[j][(j+i) % 32].reshape(9)[0].detach(), 256))\n",
    "        k2 = np.append(k2, np.repeat(model.layer2[2].conv1.weight[j][(j+i) % 32].reshape(9)[1].detach(), 256))\n",
    "        k3 = np.append(k3, np.repeat(model.layer2[2].conv1.weight[j][(j+i) % 32].reshape(9)[2].detach(), 256))\n",
    "        k4 = np.append(k4, np.repeat(model.layer2[2].conv1.weight[j][(j+i) % 32].reshape(9)[3].detach(), 256))\n",
    "        k5 = np.append(k5, np.repeat(model.layer2[2].conv1.weight[j][(j+i) % 32].reshape(9)[4].detach(), 256))\n",
    "        k6 = np.append(k6, np.repeat(model.layer2[2].conv1.weight[j][(j+i) % 32].reshape(9)[5].detach(), 256))\n",
    "        k7 = np.append(k7, np.repeat(model.layer2[2].conv1.weight[j][(j+i) % 32].reshape(9)[6].detach(), 256))\n",
    "        k8 = np.append(k8, np.repeat(model.layer2[2].conv1.weight[j][(j+i) % 32].reshape(9)[7].detach(), 256))\n",
    "        k9 = np.append(k9, np.repeat(model.layer2[2].conv1.weight[j][(j+i) % 32].reshape(9)[8].detach(), 256))\n",
    "\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 256))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 256))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 256))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 256))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 256))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 256))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 256))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 256))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 256))\n",
    "    \n",
    "    mul1 = np.roll(k1, 256 * i)\n",
    "    mul2 = np.roll(k2, 256 * i)\n",
    "    mul3 = np.roll(k3, 256 * i)\n",
    "    mul4 = np.roll(k4, 256 * i)\n",
    "    mul5 = np.roll(k5, 256 * i)\n",
    "    mul6 = np.roll(k6, 256 * i)\n",
    "    mul7 = np.roll(k7, 256 * i)\n",
    "    mul8 = np.roll(k8, 256 * i)\n",
    "    mul9 = np.roll(k9, 256 * i)\n",
    "    \n",
    "    np.savetxt('weights/layer6-conv1bn1-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv1bn1-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv1bn1-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv1bn1-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv1bn1-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv1bn1-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv1bn1-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv1bn1-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv1bn1-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "\n",
    "np.savetxt('weights/layer6-conv1bn1-bias.bin', np.repeat(b.detach(), 256), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82733d",
   "metadata": {},
   "source": [
    "## Layer2[2]: Conv2+Bn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2499ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.layer2[2].bn2.weight / torch.sqrt(model.layer2[2].bn2.running_var + model.layer2[2].bn2.eps)\n",
    "b = -(model.layer2[2].bn2.weight * model.layer2[2].bn2.running_mean / torch.sqrt(model.layer2[2].bn2.running_var + model.layer2[2].bn2.eps)) + model.layer2[2].bn2.bias\n",
    "\n",
    "ks = []\n",
    "\n",
    "for i in range(32):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "\n",
    "    for j in range(32):\n",
    "        #Qua moltiplico np.repeat blabla per A[j]\n",
    "        k1 = np.append(k1, np.repeat(model.layer2[2].conv2.weight[j][(j+i) % 32].reshape(9)[0].detach(), 256))\n",
    "        k2 = np.append(k2, np.repeat(model.layer2[2].conv2.weight[j][(j+i) % 32].reshape(9)[1].detach(), 256))\n",
    "        k3 = np.append(k3, np.repeat(model.layer2[2].conv2.weight[j][(j+i) % 32].reshape(9)[2].detach(), 256))\n",
    "        k4 = np.append(k4, np.repeat(model.layer2[2].conv2.weight[j][(j+i) % 32].reshape(9)[3].detach(), 256))\n",
    "        k5 = np.append(k5, np.repeat(model.layer2[2].conv2.weight[j][(j+i) % 32].reshape(9)[4].detach(), 256))\n",
    "        k6 = np.append(k6, np.repeat(model.layer2[2].conv2.weight[j][(j+i) % 32].reshape(9)[5].detach(), 256))\n",
    "        k7 = np.append(k7, np.repeat(model.layer2[2].conv2.weight[j][(j+i) % 32].reshape(9)[6].detach(), 256))\n",
    "        k8 = np.append(k8, np.repeat(model.layer2[2].conv2.weight[j][(j+i) % 32].reshape(9)[7].detach(), 256))\n",
    "        k9 = np.append(k9, np.repeat(model.layer2[2].conv2.weight[j][(j+i) % 32].reshape(9)[8].detach(), 256))\n",
    "\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 256))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 256))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 256))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 256))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 256))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 256))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 256))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 256))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 256))\n",
    "    \n",
    "    mul1 = np.roll(k1, 256 * i)\n",
    "    mul2 = np.roll(k2, 256 * i)\n",
    "    mul3 = np.roll(k3, 256 * i)\n",
    "    mul4 = np.roll(k4, 256 * i)\n",
    "    mul5 = np.roll(k5, 256 * i)\n",
    "    mul6 = np.roll(k6, 256 * i)\n",
    "    mul7 = np.roll(k7, 256 * i)\n",
    "    mul8 = np.roll(k8, 256 * i)\n",
    "    mul9 = np.roll(k9, 256 * i)\n",
    "    \n",
    "    np.savetxt('weights/layer6-conv2bn2-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv2bn2-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv2bn2-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv2bn2-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv2bn2-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv2bn2-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv2bn2-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv2bn2-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer6-conv2bn2-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "\n",
    "np.savetxt('weights/layer6-conv2bn2-bias.bin', np.repeat(b.detach(), 256), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d50c4cf",
   "metadata": {},
   "source": [
    "## Layer3[0]: Conv1+Bn1 SX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0f2ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 16\n",
    "padding = 1\n",
    "\n",
    "bin_mask1 = np.tile(np.array(build_mask(img_width + 1, 0, img_width -1, img_width ** 2)), 32)\n",
    "bin_mask2 = np.tile(np.array(build_mask(img_width, 0, img_width ** 2, img_width ** 2)), 32)\n",
    "bin_mask3 = np.tile(np.array(build_mask(img_width, 0, img_width - 1, img_width ** 2)), 32)\n",
    "bin_mask4 = np.tile(np.array(build_mask(1, 0, img_width - 1, img_width ** 2)), 32)\n",
    "bin_mask5 = np.tile(np.array(build_mask(0, 0, img_width ** 2, img_width ** 2)), 32)\n",
    "bin_mask6 = np.tile(np.array(build_mask(0, 1, img_width - 1, img_width ** 2)), 32)\n",
    "bin_mask7 = np.tile(np.array(build_mask(1, img_width - 1, img_width - 1, img_width ** 2)), 32)\n",
    "bin_mask8 = np.tile(np.array(build_mask(0, img_width, img_width ** 2, img_width ** 2)), 32)\n",
    "bin_mask9 = np.tile(np.array(build_mask(0, img_width + 1, img_width - 1, img_width ** 2)), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44aebfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def altalena2(v):\n",
    "    new_v = []\n",
    "    for i in range(len(v)):\n",
    "        if i % 2 != 0:\n",
    "            new_v.append(0)\n",
    "        elif i % 32 >= 16 and i % 32 < 32:\n",
    "            new_v.append(0)\n",
    "        else:\n",
    "            new_v.append(v[i])\n",
    "    return new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bceda0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([0.7852, 0.6988, 0.7153, 0.5844, 0.7026, 0.5671, 0.7342, 0.7735, 0.6820,\n",
      "        0.6612, 0.5970, 0.5450, 0.6615, 0.6018, 0.6589, 0.7381, 0.7584, 0.6420,\n",
      "        0.7446, 0.6767, 0.8471, 0.6572, 0.7782, 0.6296, 0.7325, 0.5878, 0.7295,\n",
      "        0.7023, 0.5688, 0.6702, 0.5775, 0.8381, 0.5502, 0.6512, 0.6194, 0.7252,\n",
      "        0.6100, 0.7107, 0.6952, 0.4918, 0.6784, 0.7418, 0.8401, 0.6253, 0.6673,\n",
      "        0.6501, 0.6103, 0.7182, 0.7388, 0.7017, 0.7574, 0.7854, 0.7315, 0.6495,\n",
      "        0.7971, 0.6357, 0.6459, 0.5802, 0.7215, 0.6131, 0.7307, 0.6417, 0.7794,\n",
      "        0.8286], grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([-0.1588,  0.0817,  0.2918,  0.1824,  0.0592, -0.2113, -0.0125, -0.3414,\n",
      "         0.0232, -0.0052, -0.2336, -0.1512,  0.1029,  0.3411,  0.2257, -0.0721,\n",
      "         0.3679,  0.2816, -0.2067,  0.3021,  0.0033,  0.2673, -0.0598,  0.0198,\n",
      "         0.2362,  0.0603,  0.0112,  0.1465,  0.8076,  0.4792, -0.0515, -0.0544,\n",
      "         0.1555,  0.3247, -0.2614, -0.2994, -0.1041, -0.2443, -0.0653,  0.0770,\n",
      "        -0.1039, -0.0539, -0.0478,  0.2099, -0.0670, -0.3548,  0.1346,  0.1423,\n",
      "        -0.5049,  0.1840,  0.3229,  0.0037, -0.1210, -0.2651, -0.1518,  0.1736,\n",
      "         0.3036,  0.4518,  0.0405, -0.0693, -0.1548, -0.0988, -0.4061, -0.1195],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A = model.layer3[0].bn1.weight / torch.sqrt(model.layer3[0].bn1.running_var + model.layer3[0].bn1.eps)\n",
    "b = -(model.layer3[0].bn1.weight * model.layer3[0].bn1.running_mean / torch.sqrt(model.layer3[0].bn1.running_var + model.layer3[0].bn1.eps)) + model.layer3[0].bn1.bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "channels = []\n",
    "\n",
    "for i in range(32):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "    \n",
    "    for j in range(64):\n",
    "        k1 = np.append(k1, np.repeat(model.layer3[0].conv1.weight[j][(j+i) % 32].reshape(9)[0].detach(), 256))\n",
    "        k2 = np.append(k2, np.repeat(model.layer3[0].conv1.weight[j][(j+i) % 32].reshape(9)[1].detach(), 256))\n",
    "        k3 = np.append(k3, np.repeat(model.layer3[0].conv1.weight[j][(j+i) % 32].reshape(9)[2].detach(), 256))\n",
    "        k4 = np.append(k4, np.repeat(model.layer3[0].conv1.weight[j][(j+i) % 32].reshape(9)[3].detach(), 256))\n",
    "        k5 = np.append(k5, np.repeat(model.layer3[0].conv1.weight[j][(j+i) % 32].reshape(9)[4].detach(), 256))\n",
    "        k6 = np.append(k6, np.repeat(model.layer3[0].conv1.weight[j][(j+i) % 32].reshape(9)[5].detach(), 256))\n",
    "        k7 = np.append(k7, np.repeat(model.layer3[0].conv1.weight[j][(j+i) % 32].reshape(9)[6].detach(), 256))\n",
    "        k8 = np.append(k8, np.repeat(model.layer3[0].conv1.weight[j][(j+i) % 32].reshape(9)[7].detach(), 256))\n",
    "        k9 = np.append(k9, np.repeat(model.layer3[0].conv1.weight[j][(j+i) % 32].reshape(9)[8].detach(), 256))\n",
    "    \n",
    "    k1 = np.multiply(k1, altalena2(np.tile(bin_mask1, 2)))\n",
    "    k2 = np.multiply(k2, altalena2(np.tile(bin_mask2, 2)))\n",
    "    k3 = np.multiply(k3, altalena2(np.tile(bin_mask3, 2)))\n",
    "    k4 = np.multiply(k4, altalena2(np.tile(bin_mask4, 2)))\n",
    "    k5 = np.multiply(k5, altalena2(np.tile(bin_mask5, 2)))\n",
    "    k6 = np.multiply(k6, altalena2(np.tile(bin_mask6, 2)))\n",
    "    k7 = np.multiply(k7, altalena2(np.tile(bin_mask7, 2)))\n",
    "    k8 = np.multiply(k8, altalena2(np.tile(bin_mask8, 2)))\n",
    "    k9 = np.multiply(k9, altalena2(np.tile(bin_mask9, 2)))\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach().numpy(), 256))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach().numpy(), 256))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach().numpy(), 256))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach().numpy(), 256))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach().numpy(), 256))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach().numpy(), 256))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach().numpy(), 256))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach().numpy(), 256))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach().numpy(), 256))\n",
    "\n",
    "    \n",
    "    #Affianco CH1[0]-CH16[0]-CH1[1]-CH16[1]-CH1[2]...\n",
    "    k1 = np.add(k1, np.roll(k1, -8192 + 1))[:8192]\n",
    "    k2 = np.add(k2, np.roll(k2, -8192 + 1))[:8192]\n",
    "    k3 = np.add(k3, np.roll(k3, -8192 + 1))[:8192]\n",
    "    k4 = np.add(k4, np.roll(k4, -8192 + 1))[:8192]\n",
    "    k5 = np.add(k5, np.roll(k5, -8192 + 1))[:8192]\n",
    "    k6 = np.add(k6, np.roll(k6, -8192 + 1))[:8192]\n",
    "    k7 = np.add(k7, np.roll(k7, -8192 + 1))[:8192]\n",
    "    k8 = np.add(k8, np.roll(k8, -8192 + 1))[:8192]\n",
    "    k9 = np.add(k9, np.roll(k9, -8192 + 1))[:8192]\n",
    "\n",
    "    \n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k1.bin'.format(i), altalena2(np.roll(k1, 256 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k1.bin'.format(i+32), altalena2(np.roll(k1, 256 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k2.bin'.format(i), altalena2(np.roll(k2, 256 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k2.bin'.format(i+32), altalena2(np.roll(k2, 256 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k3.bin'.format(i), altalena2(np.roll(k3, 256 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k3.bin'.format(i+32), altalena2(np.roll(k3, 256 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k4.bin'.format(i), altalena2(np.roll(k4, 256 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k4.bin'.format(i+32), altalena2(np.roll(k4, 256 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k5.bin'.format(i), altalena2(np.roll(k5, 256 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k5.bin'.format(i+32), altalena2(np.roll(k5, 256 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k6.bin'.format(i), altalena2(np.roll(k6, 256 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k6.bin'.format(i+32), altalena2(np.roll(k6, 256 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k7.bin'.format(i), altalena2(np.roll(k7, 256 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k7.bin'.format(i+32), altalena2(np.roll(k7, 256 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k8.bin'.format(i), altalena2(np.roll(k8, 256 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k8.bin'.format(i+32), altalena2(np.roll(k8, 256 * i - 1)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k9.bin'.format(i), altalena2(np.roll(k9, 256 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv1bn1-ch{}-k9.bin'.format(i+32), altalena2(np.roll(k9, 256 * i - 1)), delimiter=',')\n",
    "    \n",
    "    \n",
    "bias_corrected = np.add(altalena2(np.repeat(b.detach().numpy(),256)), np.roll(altalena2(np.repeat(b.detach().numpy(),256)), -8192 + 1))[:8192]\n",
    "bias_corrected016 = altalena2(np.repeat(b.detach().numpy()[:32], 256))\n",
    "bias_corrected1632 = altalena2(np.roll(np.repeat(b.detach().numpy()[32:64], 256), -1))\n",
    "\n",
    "np.savetxt('weights/layer7-conv1bn1-bias1.bin'.format(i), bias_corrected016, delimiter=',')\n",
    "np.savetxt('weights/layer7-conv1bn1-bias2.bin'.format(i), bias_corrected1632, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dfd99c",
   "metadata": {},
   "source": [
    "## Layer3[0]: Conv1+Bn1 DX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52088246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([0.9636, 0.8384, 0.6860, 0.8404, 0.9047, 0.9746, 0.7416, 0.7377, 0.9653,\n",
      "        0.9845, 0.8502, 0.7280, 0.9929, 0.8763, 0.9123, 0.5750, 0.9231, 0.6414,\n",
      "        0.7063, 0.6996, 0.8063, 0.6810, 0.9202, 0.8036, 1.0214, 0.8607, 0.7410,\n",
      "        0.8437, 0.6967, 0.8093, 0.6429, 1.3858, 0.6277, 0.7279, 1.0041, 0.7585,\n",
      "        0.8431, 0.5789, 0.6564, 0.7140, 0.7016, 0.7634, 0.8902, 0.8297, 0.9412,\n",
      "        0.7452, 0.8048, 0.6787, 0.9225, 0.7063, 0.5947, 0.9477, 0.7277, 0.6615,\n",
      "        0.8845, 0.8250, 0.7366, 0.8169, 0.8526, 1.0482, 1.0458, 0.7799, 0.8699,\n",
      "        0.8760], grad_fn=<DivBackward0>)\n",
      "\n",
      "b: tensor([-2.6746e-02, -5.8056e-02, -2.9641e-03,  2.9841e-02, -3.3699e-02,\n",
      "        -2.0143e-02,  5.4205e-02,  7.4022e-06,  4.4684e-03, -8.3803e-02,\n",
      "        -3.9280e-03, -1.4146e-02, -6.6965e-02, -5.8474e-02, -1.7255e-01,\n",
      "        -4.2936e-02,  5.7749e-02, -1.0887e-01, -6.1774e-02, -1.0028e-01,\n",
      "        -5.6817e-02, -1.2174e-01, -3.0950e-02,  1.1160e-02, -1.2527e-01,\n",
      "        -2.3630e-02, -7.3470e-02, -1.3804e-01, -5.0762e-02,  2.6540e-02,\n",
      "        -1.2714e-01, -6.4407e-02, -8.2573e-02, -6.8810e-02, -1.4606e-01,\n",
      "        -1.0230e-02,  2.3856e-01, -1.2183e-02, -2.1269e-03, -1.2812e-01,\n",
      "         1.9506e-02,  4.3864e-02, -8.4435e-02,  1.5579e-01, -7.4900e-02,\n",
      "        -6.6437e-02,  1.3594e-02,  9.3043e-02, -1.7066e-01,  1.0441e-02,\n",
      "        -3.4544e-02,  5.6366e-02, -2.3077e-02,  1.2781e-01,  1.3977e-02,\n",
      "        -1.4542e-01, -2.3379e-02, -1.2753e-02,  1.7494e-03, -7.3396e-02,\n",
      "        -5.0090e-02, -9.8890e-02, -5.1879e-02, -2.1388e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "-0.0505001649674488\n",
      "-0.047736714525068225\n",
      "-0.012603078641380938\n",
      "0.059798372977229564\n",
      "-0.03556010464399262\n",
      "0.08465145413188191\n",
      "-0.019612008160897476\n",
      "0.0903924136449179\n",
      "0.03495098842255495\n",
      "0.029021870607103817\n",
      "-0.0741689850857723\n",
      "-0.010856200284755924\n",
      "-0.026033417028992756\n",
      "-0.013059753380774253\n",
      "0.07646206938582001\n",
      "-0.0608265715830405\n",
      "0.015695550806955616\n",
      "0.017880604311206305\n",
      "-0.006159987156924285\n",
      "-0.0025115603059832903\n",
      "-0.013008995490424446\n",
      "-0.05375764379983283\n",
      "0.043193929105395545\n",
      "0.006260594335311759\n",
      "-0.009332229669887226\n",
      "-0.06679702474634519\n",
      "-0.01549138854045684\n",
      "-0.0014380286143185136\n",
      "-0.06482817641528849\n",
      "-0.10339870980126342\n",
      "-0.010331572861034644\n",
      "-0.03866554492019714\n"
     ]
    }
   ],
   "source": [
    "A = model.layer3[0].downsample[1].weight / torch.sqrt(model.layer3[0].downsample[1].running_var + model.layer3[0].downsample[1].eps)\n",
    "b = -(model.layer3[0].downsample[1].weight * model.layer3[0].downsample[1].running_mean / torch.sqrt(model.layer3[0].downsample[1].running_var + model.layer3[0].downsample[1].eps)) + model.layer3[0].downsample[1].bias\n",
    "print(\"A: {}\\n\\nb: {}\".format(A, b))\n",
    "\n",
    "for i in range(32):\n",
    "    k1 = np.array([])\n",
    "    \n",
    "    for j in range(64):\n",
    "        k1 = np.append(k1, np.repeat(model.layer3[0].downsample[0].weight[j][(j+i) % 32].reshape(1)[0].detach(), 256))\n",
    "    \n",
    "    k1 = np.multiply(k1, altalena2(np.tile(bin_mask5, 2)))\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach().numpy(), 256))\n",
    "    \n",
    "    #Affianco CH1[0]-CH16[0]-CH1[1]-CH16[1]-CH1[2]...\n",
    "    k1 = np.add(k1, np.roll(k1, -8192 + 1))[:8192]\n",
    "    \n",
    "    print(k1[0])\n",
    "\n",
    "    np.savetxt('weights/layer7dx-conv1bn1-ch{}-k1.bin'.format(i), altalena2(np.roll(k1, 256 * i)), delimiter=',')\n",
    "    np.savetxt('weights/layer7dx-conv1bn1-ch{}-k1.bin'.format(i+32), altalena2(np.roll(k1, 256 * i - 1)), delimiter=',')\n",
    "    \n",
    "bias_corrected016 = altalena2(np.repeat(b.detach().numpy()[:32], 256))\n",
    "bias_corrected1632 = altalena2(np.roll(np.repeat(b.detach().numpy()[32:64], 256), -1))\n",
    "#bias_corrected = np.add(altalena(np.repeat(b.detach().numpy(),1024)), np.roll(altalena(np.repeat(b.detach().numpy(),1024)), -16384 + 1))[:16384]\n",
    "#bias_corrected016 = altalena(np.repeat(b.detach().numpy()[:16], 1024))\n",
    "#bias_corrected1632 = altalena(np.repeat(b.detach().numpy()[16:32], 1024))\n",
    "\n",
    "np.savetxt('weights/layer7dx-conv1bn1-bias1.bin'.format(i), bias_corrected016, delimiter=',')\n",
    "np.savetxt('weights/layer7dx-conv1bn1-bias2.bin'.format(i), bias_corrected1632, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5fc1f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 8\n",
    "padding = 1\n",
    "\n",
    "bin_mask1 = np.tile(np.array(build_mask(img_width + 1, 0, img_width -1, img_width ** 2)), 64)\n",
    "bin_mask2 = np.tile(np.array(build_mask(img_width, 0, img_width ** 2, img_width ** 2)), 64)\n",
    "bin_mask3 = np.tile(np.array(build_mask(img_width, 0, img_width - 1, img_width ** 2)), 64)\n",
    "bin_mask4 = np.tile(np.array(build_mask(1, 0, img_width - 1, img_width ** 2)), 64)\n",
    "bin_mask5 = np.tile(np.array(build_mask(0, 0, img_width ** 2, img_width ** 2)), 64)\n",
    "bin_mask6 = np.tile(np.array(build_mask(0, 1, img_width - 1, img_width ** 2)), 64)\n",
    "bin_mask7 = np.tile(np.array(build_mask(1, img_width - 1, img_width - 1, img_width ** 2)), 64)\n",
    "bin_mask8 = np.tile(np.array(build_mask(0, img_width, img_width ** 2, img_width ** 2)), 64)\n",
    "bin_mask9 = np.tile(np.array(build_mask(0, img_width + 1, img_width - 1, img_width ** 2)), 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542eddd2",
   "metadata": {},
   "source": [
    "## Layer3[0]: Conv2+Bn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09e01959",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.layer3[0].bn2.weight / torch.sqrt(model.layer3[0].bn2.running_var + model.layer3[0].bn2.eps)\n",
    "b = -(model.layer3[0].bn2.weight * model.layer3[0].bn2.running_mean / torch.sqrt(model.layer3[0].bn2.running_var + model.layer3[0].bn2.eps)) + model.layer3[0].bn2.bias\n",
    "\n",
    "ks = []\n",
    "\n",
    "for i in range(64):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "\n",
    "    for j in range(64):\n",
    "        #Qua moltiplico np.repeat blabla per A[j]\n",
    "        k1 = np.append(k1, np.repeat(model.layer3[0].conv2.weight[j][(j+i) % 64].reshape(9)[0].detach(), 64))\n",
    "        k2 = np.append(k2, np.repeat(model.layer3[0].conv2.weight[j][(j+i) % 64].reshape(9)[1].detach(), 64))\n",
    "        k3 = np.append(k3, np.repeat(model.layer3[0].conv2.weight[j][(j+i) % 64].reshape(9)[2].detach(), 64))\n",
    "        k4 = np.append(k4, np.repeat(model.layer3[0].conv2.weight[j][(j+i) % 64].reshape(9)[3].detach(), 64))\n",
    "        k5 = np.append(k5, np.repeat(model.layer3[0].conv2.weight[j][(j+i) % 64].reshape(9)[4].detach(), 64))\n",
    "        k6 = np.append(k6, np.repeat(model.layer3[0].conv2.weight[j][(j+i) % 64].reshape(9)[5].detach(), 64))\n",
    "        k7 = np.append(k7, np.repeat(model.layer3[0].conv2.weight[j][(j+i) % 64].reshape(9)[6].detach(), 64))\n",
    "        k8 = np.append(k8, np.repeat(model.layer3[0].conv2.weight[j][(j+i) % 64].reshape(9)[7].detach(), 64))\n",
    "        k9 = np.append(k9, np.repeat(model.layer3[0].conv2.weight[j][(j+i) % 64].reshape(9)[8].detach(), 64))\n",
    "\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 64))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 64))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 64))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 64))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 64))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 64))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 64))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 64))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 64))\n",
    "    \n",
    "    mul1 = np.roll(k1, 64 * i)\n",
    "    mul2 = np.roll(k2, 64 * i)\n",
    "    mul3 = np.roll(k3, 64 * i)\n",
    "    mul4 = np.roll(k4, 64 * i)\n",
    "    mul5 = np.roll(k5, 64 * i)\n",
    "    mul6 = np.roll(k6, 64 * i)\n",
    "    mul7 = np.roll(k7, 64 * i)\n",
    "    mul8 = np.roll(k8, 64 * i)\n",
    "    mul9 = np.roll(k9, 64 * i)\n",
    "    \n",
    "    np.savetxt('weights/layer7-conv2bn2-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv2bn2-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv2bn2-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv2bn2-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv2bn2-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv2bn2-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv2bn2-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv2bn2-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer7-conv2bn2-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "\n",
    "np.savetxt('weights/layer7-conv2bn2-bias.bin', np.repeat(b.detach(), 64), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67a194",
   "metadata": {},
   "source": [
    "## Layer3[1]: Conv1+Bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aeb9ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.layer3[1].bn1.weight / torch.sqrt(model.layer3[1].bn1.running_var + model.layer3[1].bn1.eps)\n",
    "b = -(model.layer3[1].bn1.weight * model.layer3[1].bn1.running_mean / torch.sqrt(model.layer3[1].bn1.running_var + model.layer3[1].bn1.eps)) + model.layer3[1].bn1.bias\n",
    "\n",
    "ks = []\n",
    "\n",
    "for i in range(64):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "\n",
    "    for j in range(64):\n",
    "        #Qua moltiplico np.repeat blabla per A[j]\n",
    "        k1 = np.append(k1, np.repeat(model.layer3[1].conv1.weight[j][(j+i) % 64].reshape(9)[0].detach(), 64))\n",
    "        k2 = np.append(k2, np.repeat(model.layer3[1].conv1.weight[j][(j+i) % 64].reshape(9)[1].detach(), 64))\n",
    "        k3 = np.append(k3, np.repeat(model.layer3[1].conv1.weight[j][(j+i) % 64].reshape(9)[2].detach(), 64))\n",
    "        k4 = np.append(k4, np.repeat(model.layer3[1].conv1.weight[j][(j+i) % 64].reshape(9)[3].detach(), 64))\n",
    "        k5 = np.append(k5, np.repeat(model.layer3[1].conv1.weight[j][(j+i) % 64].reshape(9)[4].detach(), 64))\n",
    "        k6 = np.append(k6, np.repeat(model.layer3[1].conv1.weight[j][(j+i) % 64].reshape(9)[5].detach(), 64))\n",
    "        k7 = np.append(k7, np.repeat(model.layer3[1].conv1.weight[j][(j+i) % 64].reshape(9)[6].detach(), 64))\n",
    "        k8 = np.append(k8, np.repeat(model.layer3[1].conv1.weight[j][(j+i) % 64].reshape(9)[7].detach(), 64))\n",
    "        k9 = np.append(k9, np.repeat(model.layer3[1].conv1.weight[j][(j+i) % 64].reshape(9)[8].detach(), 64))\n",
    "\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 64))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 64))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 64))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 64))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 64))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 64))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 64))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 64))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 64))\n",
    "    \n",
    "    mul1 = np.roll(k1, 64 * i)\n",
    "    mul2 = np.roll(k2, 64 * i)\n",
    "    mul3 = np.roll(k3, 64 * i)\n",
    "    mul4 = np.roll(k4, 64 * i)\n",
    "    mul5 = np.roll(k5, 64 * i)\n",
    "    mul6 = np.roll(k6, 64 * i)\n",
    "    mul7 = np.roll(k7, 64 * i)\n",
    "    mul8 = np.roll(k8, 64 * i)\n",
    "    mul9 = np.roll(k9, 64 * i)\n",
    "    \n",
    "    np.savetxt('weights/layer8-conv1bn1-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv1bn1-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv1bn1-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv1bn1-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv1bn1-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv1bn1-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv1bn1-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv1bn1-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv1bn1-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "\n",
    "np.savetxt('weights/layer8-conv1bn1-bias.bin', np.repeat(b.detach(), 64), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f055ba",
   "metadata": {},
   "source": [
    "## Layer3[1]: Conv2+Bn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47a51960",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.layer3[1].bn2.weight / torch.sqrt(model.layer3[1].bn2.running_var + model.layer3[1].bn2.eps)\n",
    "b = -(model.layer3[1].bn2.weight * model.layer3[1].bn2.running_mean / torch.sqrt(model.layer3[1].bn2.running_var + model.layer3[1].bn2.eps)) + model.layer3[1].bn2.bias\n",
    "\n",
    "ks = []\n",
    "\n",
    "for i in range(64):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "\n",
    "    for j in range(64):\n",
    "        #Qua moltiplico np.repeat blabla per A[j]\n",
    "        k1 = np.append(k1, np.repeat(model.layer3[1].conv2.weight[j][(j+i) % 64].reshape(9)[0].detach(), 64))\n",
    "        k2 = np.append(k2, np.repeat(model.layer3[1].conv2.weight[j][(j+i) % 64].reshape(9)[1].detach(), 64))\n",
    "        k3 = np.append(k3, np.repeat(model.layer3[1].conv2.weight[j][(j+i) % 64].reshape(9)[2].detach(), 64))\n",
    "        k4 = np.append(k4, np.repeat(model.layer3[1].conv2.weight[j][(j+i) % 64].reshape(9)[3].detach(), 64))\n",
    "        k5 = np.append(k5, np.repeat(model.layer3[1].conv2.weight[j][(j+i) % 64].reshape(9)[4].detach(), 64))\n",
    "        k6 = np.append(k6, np.repeat(model.layer3[1].conv2.weight[j][(j+i) % 64].reshape(9)[5].detach(), 64))\n",
    "        k7 = np.append(k7, np.repeat(model.layer3[1].conv2.weight[j][(j+i) % 64].reshape(9)[6].detach(), 64))\n",
    "        k8 = np.append(k8, np.repeat(model.layer3[1].conv2.weight[j][(j+i) % 64].reshape(9)[7].detach(), 64))\n",
    "        k9 = np.append(k9, np.repeat(model.layer3[1].conv2.weight[j][(j+i) % 64].reshape(9)[8].detach(), 64))\n",
    "\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 64))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 64))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 64))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 64))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 64))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 64))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 64))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 64))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 64))\n",
    "    \n",
    "    mul1 = np.roll(k1, 64 * i)\n",
    "    mul2 = np.roll(k2, 64 * i)\n",
    "    mul3 = np.roll(k3, 64 * i)\n",
    "    mul4 = np.roll(k4, 64 * i)\n",
    "    mul5 = np.roll(k5, 64 * i)\n",
    "    mul6 = np.roll(k6, 64 * i)\n",
    "    mul7 = np.roll(k7, 64 * i)\n",
    "    mul8 = np.roll(k8, 64 * i)\n",
    "    mul9 = np.roll(k9, 64 * i)\n",
    "    \n",
    "    np.savetxt('weights/layer8-conv2bn2-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv2bn2-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv2bn2-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv2bn2-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv2bn2-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv2bn2-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv2bn2-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv2bn2-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer8-conv2bn2-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "\n",
    "np.savetxt('weights/layer8-conv2bn2-bias.bin', np.repeat(b.detach(), 64), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9da5e",
   "metadata": {},
   "source": [
    "## Layer3[2]: Conv1+Bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbfc8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.layer3[2].bn1.weight / torch.sqrt(model.layer3[2].bn1.running_var + model.layer3[2].bn1.eps)\n",
    "b = -(model.layer3[2].bn1.weight * model.layer3[2].bn1.running_mean / torch.sqrt(model.layer3[2].bn1.running_var + model.layer3[2].bn1.eps)) + model.layer3[2].bn1.bias\n",
    "\n",
    "ks = []\n",
    "\n",
    "for i in range(64):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "\n",
    "    for j in range(64):\n",
    "        #Qua moltiplico np.repeat blabla per A[j]\n",
    "        k1 = np.append(k1, np.repeat(model.layer3[2].conv1.weight[j][(j+i) % 64].reshape(9)[0].detach(), 64))\n",
    "        k2 = np.append(k2, np.repeat(model.layer3[2].conv1.weight[j][(j+i) % 64].reshape(9)[1].detach(), 64))\n",
    "        k3 = np.append(k3, np.repeat(model.layer3[2].conv1.weight[j][(j+i) % 64].reshape(9)[2].detach(), 64))\n",
    "        k4 = np.append(k4, np.repeat(model.layer3[2].conv1.weight[j][(j+i) % 64].reshape(9)[3].detach(), 64))\n",
    "        k5 = np.append(k5, np.repeat(model.layer3[2].conv1.weight[j][(j+i) % 64].reshape(9)[4].detach(), 64))\n",
    "        k6 = np.append(k6, np.repeat(model.layer3[2].conv1.weight[j][(j+i) % 64].reshape(9)[5].detach(), 64))\n",
    "        k7 = np.append(k7, np.repeat(model.layer3[2].conv1.weight[j][(j+i) % 64].reshape(9)[6].detach(), 64))\n",
    "        k8 = np.append(k8, np.repeat(model.layer3[2].conv1.weight[j][(j+i) % 64].reshape(9)[7].detach(), 64))\n",
    "        k9 = np.append(k9, np.repeat(model.layer3[2].conv1.weight[j][(j+i) % 64].reshape(9)[8].detach(), 64))\n",
    "\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 64))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 64))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 64))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 64))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 64))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 64))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 64))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 64))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 64))\n",
    "    \n",
    "    mul1 = np.roll(k1, 64 * i)\n",
    "    mul2 = np.roll(k2, 64 * i)\n",
    "    mul3 = np.roll(k3, 64 * i)\n",
    "    mul4 = np.roll(k4, 64 * i)\n",
    "    mul5 = np.roll(k5, 64 * i)\n",
    "    mul6 = np.roll(k6, 64 * i)\n",
    "    mul7 = np.roll(k7, 64 * i)\n",
    "    mul8 = np.roll(k8, 64 * i)\n",
    "    mul9 = np.roll(k9, 64 * i)\n",
    "    \n",
    "    np.savetxt('weights/layer9-conv1bn1-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv1bn1-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv1bn1-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv1bn1-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv1bn1-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv1bn1-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv1bn1-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv1bn1-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv1bn1-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "\n",
    "np.savetxt('weights/layer9-conv1bn1-bias.bin', np.repeat(b.detach(), 64), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f6bec",
   "metadata": {},
   "source": [
    "## Layer3[2]: Conv2+Bn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6d8e370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.layer3[2].bn2.weight / torch.sqrt(model.layer3[2].bn2.running_var + model.layer3[2].bn2.eps)\n",
    "b = -(model.layer3[2].bn2.weight * model.layer3[2].bn2.running_mean / torch.sqrt(model.layer3[2].bn2.running_var + model.layer3[2].bn2.eps)) + model.layer3[2].bn2.bias\n",
    "\n",
    "ks = []\n",
    "\n",
    "for i in range(64):\n",
    "    k1 = np.array([])\n",
    "    k2 = np.array([])\n",
    "    k3 = np.array([])\n",
    "    k4 = np.array([])\n",
    "    k5 = np.array([])\n",
    "    k6 = np.array([])\n",
    "    k7 = np.array([])\n",
    "    k8 = np.array([])\n",
    "    k9 = np.array([])\n",
    "\n",
    "    for j in range(64):\n",
    "        #Qua moltiplico np.repeat blabla per A[j]\n",
    "        k1 = np.append(k1, np.repeat(model.layer3[2].conv2.weight[j][(j+i) % 64].reshape(9)[0].detach(), 64))\n",
    "        k2 = np.append(k2, np.repeat(model.layer3[2].conv2.weight[j][(j+i) % 64].reshape(9)[1].detach(), 64))\n",
    "        k3 = np.append(k3, np.repeat(model.layer3[2].conv2.weight[j][(j+i) % 64].reshape(9)[2].detach(), 64))\n",
    "        k4 = np.append(k4, np.repeat(model.layer3[2].conv2.weight[j][(j+i) % 64].reshape(9)[3].detach(), 64))\n",
    "        k5 = np.append(k5, np.repeat(model.layer3[2].conv2.weight[j][(j+i) % 64].reshape(9)[4].detach(), 64))\n",
    "        k6 = np.append(k6, np.repeat(model.layer3[2].conv2.weight[j][(j+i) % 64].reshape(9)[5].detach(), 64))\n",
    "        k7 = np.append(k7, np.repeat(model.layer3[2].conv2.weight[j][(j+i) % 64].reshape(9)[6].detach(), 64))\n",
    "        k8 = np.append(k8, np.repeat(model.layer3[2].conv2.weight[j][(j+i) % 64].reshape(9)[7].detach(), 64))\n",
    "        k9 = np.append(k9, np.repeat(model.layer3[2].conv2.weight[j][(j+i) % 64].reshape(9)[8].detach(), 64))\n",
    "\n",
    "    k1 = np.multiply(k1, bin_mask1)\n",
    "    k2 = np.multiply(k2, bin_mask2)\n",
    "    k3 = np.multiply(k3, bin_mask3)\n",
    "    k4 = np.multiply(k4, bin_mask4)\n",
    "    k5 = np.multiply(k5, bin_mask5)\n",
    "    k6 = np.multiply(k6, bin_mask6)\n",
    "    k7 = np.multiply(k7, bin_mask7)\n",
    "    k8 = np.multiply(k8, bin_mask8)\n",
    "    k9 = np.multiply(k9, bin_mask9)\n",
    "\n",
    "    k1 = np.multiply(k1, np.repeat(A.detach(), 64))\n",
    "    k2 = np.multiply(k2, np.repeat(A.detach(), 64))\n",
    "    k3 = np.multiply(k3, np.repeat(A.detach(), 64))\n",
    "    k4 = np.multiply(k4, np.repeat(A.detach(), 64))\n",
    "    k5 = np.multiply(k5, np.repeat(A.detach(), 64))\n",
    "    k6 = np.multiply(k6, np.repeat(A.detach(), 64))\n",
    "    k7 = np.multiply(k7, np.repeat(A.detach(), 64))\n",
    "    k8 = np.multiply(k8, np.repeat(A.detach(), 64))\n",
    "    k9 = np.multiply(k9, np.repeat(A.detach(), 64))\n",
    "    \n",
    "    mul1 = np.roll(k1, 64 * i)\n",
    "    mul2 = np.roll(k2, 64 * i)\n",
    "    mul3 = np.roll(k3, 64 * i)\n",
    "    mul4 = np.roll(k4, 64 * i)\n",
    "    mul5 = np.roll(k5, 64 * i)\n",
    "    mul6 = np.roll(k6, 64 * i)\n",
    "    mul7 = np.roll(k7, 64 * i)\n",
    "    mul8 = np.roll(k8, 64 * i)\n",
    "    mul9 = np.roll(k9, 64 * i)\n",
    "    \n",
    "    np.savetxt('weights/layer9-conv2bn2-ch{}-k1.bin'.format(i), mul1, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv2bn2-ch{}-k2.bin'.format(i), mul2, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv2bn2-ch{}-k3.bin'.format(i), mul3, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv2bn2-ch{}-k4.bin'.format(i), mul4, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv2bn2-ch{}-k5.bin'.format(i), mul5, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv2bn2-ch{}-k6.bin'.format(i), mul6, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv2bn2-ch{}-k7.bin'.format(i), mul7, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv2bn2-ch{}-k8.bin'.format(i), mul8, delimiter=',')\n",
    "    np.savetxt('weights/layer9-conv2bn2-ch{}-k9.bin'.format(i), mul9, delimiter=',')\n",
    "\n",
    "np.savetxt('weights/layer9-conv2bn2-bias.bin', np.repeat(b.detach(), 64), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc4f14",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7e3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('weights/fc.bin', model.fc.weight.t().reshape(-1).detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
